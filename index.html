<!DOCTYPE HTML>
<html>

<head>
    <title>Jad Abou-Chakra - QUT Centre for Robotics</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1000">
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css?family=Roboto:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&&display=swap');
    </style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-EQ5ZWR13W4"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-EQ5ZWR13W4');
    </script>
    
</head>

<body id="body">
    <div id="main">
        <div id="intro">
            <div id="intro-image">
                <img src="images/jad-profile.jpg" alt="Jad Abou-Chakra">
            </div>
            <div id="intro-text">
                <h1 style="font-weight: bolder; line-height: 2em; font-size:3em">Jad Abou-Chakra</h1>
                <p>
                    Hi there! I am currently pursuing a PhD at the <a
                        href="https://www.qut.edu.au/research/centre-for-robotics">QUT Centre for Robotics</a> where I
                    specialize in embodied intelligence.  My current research is dedicated to creating a real-time, physical representation of the world.
                </p>

                <div id="intro-links-container">
                    <div id="intro-links">
                        <a href="mailto:jad.chakra@hdr.qut.edu.au">Email</a>
                        <a href="https://github.com/jc211">GitHub</a>
                        <a href="https://scholar.google.com/citations?user=nRYXorUAAAAJ&hl=en">Google Scholar</a>
                        <a href="https://www.linkedin.com/in/jadchakra">LinkedIn</a>
                    </div>
                </div>
            </div>
        </div>


        <div id="research">
            <h2 style="font-weight: bolder; font-size:2.5em">Research</h2>
            <div id="research-list">

                <div class="ri">
                    <div class="ri-image">
                        <video width="100%" height="100%"
                            style="border-radius: 1em; object-fit: cover; object-position: 30%;" autoplay loop muted
                            playsinline>
                            <source src="images/deformables_real.mp4" type="video/mp4">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            <a href="https://embodied-gaussians.github.io">
                                Physically Embodied Gaussian Splatting: Embedding Physical Priors into a Visual 3D World Model For Robotics
                            </a>
                        </div>
                        <div class="ri-text-authors">
                            Jad Abou-Chakra, Krishan Rana, Feras Dayoub, Niko Suenderhauf
                        </div>
                        <div style="flex-grow: 1;"></div>
                        <div class="ri-text-links">
                            <a
                                href="https://embodied-gaussians.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://arxiv.org/abs/2406.10788">Paper</a>
                        </div>
                    </div>
                </div>

                <div class="ri">
                    <div class="ri-image">
                        <img style="object-fit: cover; animation: ltr 10s ease-in-out alternate infinite;" src="images/policydecomp.png" alt="NeRF">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            Affordance-Centric Policy Decomposition: Sample-Efficient Robot Policy Learning for Long-Horizon Manipulation
                        </div>
                        <div class="ri-text-authors">
                            Krishan Rana, Jad Abou-Chakra, Sourav Garg, Robert Lee, Ian Reid, Niko Suenderhauf
                        </div>
                        <div style="flex-grow: 1;"></div>
                        <div class="ri-text-links">
                            <a href="https://policy-decomposition.github.io/">Website</a> 
                        </div>
                    </div>
                </div>

                <div class="ri">
                    <div class="ri-image">
                        <img style="object-fit: cover; animation: ltr 6s alternate infinite;" src="images/xembodiment.webp" alt="X-Embodiment">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            <a href="">
                                Open X-Embodiment: Robotic Learning Datasets and RT-X Models
                            </a>
                        </div>
                        <div class="ri-text-authors">
                            Open X-Embodiment Worldwide Collaboration <br/> 
                            <font color="49bf9" style="font-weight: normal;"><i>&#9733; Best Paper, ICRA24 &#9733;</i></font><br>
                        </div>
                        <div style="flex-grow: 1;"></div>
                        <div class="ri-text-links">
                            <a href="https://robotics-transformer-x.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://github.com/google-deepmind/open_x_embodiment">GitHub</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://arxiv.org/abs/2310.08864">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://docs.google.com/spreadsheets/d/1rPBD77tk60AEIGZrGSODwyyzs5FgCU9Uz3h-3_t2A9g/edit#gid=0">Datasets</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/"> Blog Post </a>
                        </div>
                    </div>
                </div>

                <div class="ri">
                    <div class="ri-image">
                        <video width="100%" height="100%"
                            style="border-radius: 1em; object-fit: cover; object-position: 50%;" autoplay loop muted
                            playsinline>
                            <source src="images/particlenerf.mp4" type="video/mp4">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            <a href="https://sites.google.com/view/particlenerf">
                                ParticleNeRF: Particle based encoding for online neural radiance fields in dynamic
                                scenes
                            </a>
                        </div>
                        <div class="ri-text-authors">
                            Jad Abou-Chakra, Feras Dayoub, Niko Suenderhauf
                            <br>
                            <font color="49bf9" style="font-weight: normal;"><i>&#9733; Best Paper Honorable Mention, WACV &#9733;</i></font><br>
                        </div>
                        <div style="flex-grow: 1;"></div>
                        <div class="ri-text-links">
                            <a
                                href="https://sites.google.com/view/particlenerf">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://arxiv.org/abs/2307.01928">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://github.com/jc211/ParticleNeRF">GitHub</a>
                        </div>
                    </div>
                </div>

                <div class="ri">
                    <div class="ri-image">
                        <video width="100%" height="100%"
                            style="border-radius: 1em; object-fit: cover; object-position: 75%;" autoplay loop muted
                            playsinline>
                            <source src="images/sayplan.mp4" type="video/mp4">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning
                        </div>
                        <div class="ri-text-authors">
                            Krishan Rana, Jesse Haviland, Sourav Garg, Jad Abou-Chakra, Ian Reid, Niko Suenderhauf
                            <br>
                            <font color="49bf9" style="font-weight: normal;"><i>&#9733; Oral Presentation, CoRL &#9733;</i></font><br>
                        </div>
                        <div style="flex-grow: 1;"></div>
                        <div class="ri-text-links">
                            <a href="https://sayplan.github.io/">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://openreview.net/pdf?id=wMpOMO0Ss7a">Paper</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://youtu.be/3aMgpqnD2RY?si=0re6L_st-x-yH_Me">Video</a>
                        </div>
                    </div>
                </div>

                <div class="ri">
                    <div class="ri-image">
                        <img style="object-fit: cover; animation: ltr 3s ease-in-out alternate infinite;" src="images/foldingbyhand.gif" alt="Folding By Hand">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            <a href="https://arxiv.org/abs/2211.02832">
                                Learning Fabric Manipulation in the Real World with Human Videos
                            </a>
                        </div>
                        <div class="ri-text-authors">
                            Robert Lee, Jad Abou-Chakra, Fangyi Zhang, Peter Corke 
                            <br>
                            ICRA 2024
                        </div>
                        <div class="ri-text-links">
                            <a href="https://sites.google.com/view/foldingbyhand">Webpage</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://drive.google.com/drive/folders/1xmfUUi-g0J78YiZDfXguZ2mpC29Cm-w3?usp=drive_link">Dataset</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://arxiv.org/pdf/2211.02832.pdf">Paper</a> 
                        </div>
                    </div>
                </div>

                <div class="ri">
                    <div class="ri-image">
                        <img style="object-fit: cover; animation: ltr 3s ease-in-out alternate infinite;" src="images/densityaware.png" alt="Density-aware NeRF Ensembles">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            <a href="https://arxiv.org/abs/2209.08718">
                                Density-aware NeRF Ensembles: Quantifying Predictive Uncertainty in Neural Radiance Fields
                            </a>
                        </div>
                        <div class="ri-text-authors">
                            Niko Suenderhauf, Jad Abou-Chakra, Dimity Miller
                            <br>
                            ICRA 2023
                        </div>
                        <div style="flex-grow: 1;"></div>
                        <div class="ri-text-links">
                            <a href="https://arxiv.org/pdf/2209.08718.pdf">Paper</a> 
                        </div>
                    </div>
                </div>


                <div class="ri">
                    <div class="ri-image">
                        <img style="object-fit: cover; animation: ltr 3s ease-in-out alternate infinite;" src="images/implicitobjectmapping.png" alt="NeRF">
                    </div>
                    <div class="ri-text">
                        <div class="ri-text-title">
                            Implicit Object Reconstruction With Noisy Data
                        </div>
                        <div class="ri-text-authors">
                            Jad Abou-Chakra, Feras Dayoub, Niko Suenderhauf
                            <br>
                            IMRSS 2022 Workshop
                        </div>
                        <div style="flex-grow: 1;"></div>
                        <div class="ri-text-links">
                            <a href="https://github.com/jc211/nerf-cube-diorama-dataset">Dataset</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
                            <a href="https://arxiv.org/pdf/2204.10516.pdf">Paper</a> 
                        </div>
                    </div>
                </div>


            </div>
        </div>

        <div id="footer">
            Website template inspired by <a href="https://jonbarron.info/">Jon</a> and <a href="https://andyzeng.github.io/">Andy</a>. Feel free to <a href="https://github.com/jadchakra/jadchakra.github.io">copy</a>.</div>

    </div>

</body>

</html>
